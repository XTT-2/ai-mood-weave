<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>MoodWeave AI - å¿ƒç»ªç»‡ç½‘</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <style>
        body { margin: 0; overflow: hidden; background: #050505; font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; }
        #ui-layer { position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; flex-direction: column; justify-content: space-between; align-items: center; z-index: 10; pointer-events: none; }
        
        .header { margin-top: 50px; text-align: center; color: white; opacity: 0.8; }
        .header h1 { font-weight: 200; letter-spacing: 5px; font-size: 1.2rem; }
        
        .footer { margin-bottom: 60px; pointer-events: auto; }
        #mic-btn { width: 80px; height: 80px; border-radius: 50%; background: rgba(255, 255, 255, 0.1); border: 1px solid rgba(255, 255, 255, 0.3); backdrop-filter: blur(10px); color: white; cursor: pointer; display: flex; align-items: center; justify-content: center; transition: all 0.3s cubic-bezier(0.175, 0.885, 0.32, 1.275); -webkit-tap-highlight-color: transparent; }
        #mic-btn:active { transform: scale(0.8); background: rgba(255, 255, 255, 0.3); }
        #mic-btn.listening { border-color: #ff3e3e; box-shadow: 0 0 20px rgba(255, 62, 62, 0.5); animation: pulse 1.5s infinite; }

        @keyframes pulse { 0% { transform: scale(1); } 50% { transform: scale(1.1); } 100% { transform: scale(1); } }
        #status-text { color: white; font-size: 0.8rem; margin-top: 20px; text-align: center; opacity: 0.6; }
    </style>
</head>
<body>

    <div id="ui-layer">
        <div class="header">
            <h1>MOODWEAVE</h1>
            <p id="hint">é•¿æŒ‰è¯´è¯ï¼Œè®© AI ç¼–ç»‡ä½ çš„æƒ…ç»ª</p>
        </div>
        <div class="footer">
            <button id="mic-btn">ğŸ™ï¸</button>
            <div id="status-text">ç­‰å¾…æ„ŸçŸ¥...</div>
        </div>
    </div>

    <script>
        // --- Three.js åœºæ™¯åˆå§‹åŒ– ---
        let scene, camera, renderer, particles, geometry;
        const particleCount = 5000;
        let targetColor = new THREE.Color(0x4444ff);
        let currentScale = 1;

        function initScene() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 5;

            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            document.body.appendChild(renderer.domElement);

            // åˆ›å»ºç²’å­ç³»ç»Ÿ
            geometry = new THREE.BufferGeometry();
            const positions = new Float32Array(particleCount * 3);
            for (let i = 0; i < particleCount * 3; i++) {
                positions[i] = (Math.random() - 0.5) * 10;
            }
            geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));

            const material = new THREE.PointsMaterial({
                size: 0.03,
                color: 0x4444ff,
                transparent: true,
                opacity: 0.6,
                blending: THREE.AdditiveBlending
            });

            particles = new THREE.Points(geometry, material);
            scene.add(particles);

            window.addEventListener('resize', onWindowResize, false);
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        // --- æ ¸å¿ƒåŠ¨ç”»å¾ªç¯ ---
        function animate() {
            requestAnimationFrame(animate);
            
            const time = Date.now() * 0.0005;
            const positions = geometry.attributes.position.array;

            // è®©ç²’å­éšæ—¶é—´æ³¢åŠ¨ï¼ˆæ¨¡æ‹Ÿæµä½“æ„Ÿï¼‰
            for (let i = 0; i < particleCount; i++) {
                const i3 = i * 3;
                positions[i3 + 1] += Math.sin(time + positions[i3] * 0.5) * 0.01;
                positions[i3] += Math.cos(time + positions[i3 + 1] * 0.5) * 0.01;
            }
            geometry.attributes.position.needsUpdate = true;

            // é¢œè‰²å¹³æ»‘è¿‡æ¸¡
            particles.material.color.lerp(targetColor, 0.05);
            
            // æ—‹è½¬
            particles.rotation.y += 0.002;
            particles.rotation.z += 0.001;

            renderer.render(scene, camera);
        }

        // --- è¯­éŸ³è¯†åˆ«ä¸æƒ…ç»ªæ˜ å°„é€»è¾‘ ---
        const micBtn = document.getElementById('mic-btn');
        const statusText = document.getElementById('status-text');
        
        // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒ
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (SpeechRecognition) {
            const recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.lang = 'zh-CN';

            micBtn.addEventListener('touchstart', (e) => {
                e.preventDefault();
                micBtn.classList.add('listening');
                statusText.innerText = "æ­£åœ¨å€¾å¬...";
                recognition.start();
            });

            recognition.onresult = (event) => {
                const text = event.results[0][0].transcript;
                statusText.innerText = `â€œ${text}â€`;
                analyzeEmotion(text);
            };

            recognition.onend = () => {
                micBtn.classList.remove('listening');
            };
        } else {
            statusText.innerText = "æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«";
        }

        // ç®€æ˜“æ¨¡æ‹Ÿ AI æƒ…æ„Ÿåˆ†ææ˜ å°„è§†è§‰
        function analyzeEmotion(text) {
            // å®é™…æ¯”èµ›ä¸­è¿™é‡Œå¯ä»¥è°ƒç”¨ OpenAI API
            if (text.includes('å¼€å¿ƒ') || text.includes('å–œæ‚¦') || text.includes('æ£’')) {
                targetColor = new THREE.Color(0xffcc00); // æš–é»„è‰²
                statusText.innerText += " | æ„ŸçŸ¥åˆ°ï¼šå–œæ‚¦";
            } else if (text.includes('éš¾è¿‡') || text.includes('å‹åŠ›') || text.includes('ç´¯')) {
                targetColor = new THREE.Color(0x444444); // ç°æš—è‰²
                statusText.innerText += " | æ„ŸçŸ¥åˆ°ï¼šå‹æŠ‘";
            } else if (text.includes('ç”Ÿæ°”') || text.includes('ç«')) {
                targetColor = new THREE.Color(0xff3300); // çº¢è‰²
                statusText.innerText += " | æ„ŸçŸ¥åˆ°ï¼šæ„¤æ€’";
            } else {
                targetColor = new THREE.Color(0x00ffcc); // é’è‰²ï¼ˆå¹³é™ï¼‰
                statusText.innerText += " | æ„ŸçŸ¥åˆ°ï¼šå¹³é™";
            }
        }

        initScene();
        animate();
    </script>
</body>
</html>